{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361dfc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import RepeatedKFold, GridSearchCV, ShuffleSplit, RandomizedSearchCV\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier, DistanceMetric\n",
    "%load_ext Cython\n",
    "import cython\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "#cython: boundscheck=False, wraparound=False, nonecheck=False\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "import jupyterthemes as jt\n",
    "from jupyterthemes.stylefx import set_nb_theme\n",
    "it = iter(jt.get_themes())\n",
    "theme = next(it)\n",
    "print(\"Current Theme: \", theme)\n",
    "set_nb_theme(theme)\n",
    "#ocean / chesterish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011bdf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timetoclass(row):\n",
    "    dt_obj1 = parser.parse(row['rundate'])\n",
    "    dt_obj2 = parser.parse(row['stopdate'])\n",
    "    ans = ((dt_obj2-dt_obj1).total_seconds()+3600/2)//3600\n",
    "    if ans == 24:\n",
    "        ans = 23\n",
    "    return ans\n",
    "\n",
    "def timedif(row):\n",
    "    dt_obj1 = parser.parse(row['rundate'])\n",
    "    dt_obj2 = parser.parse(row['stopdate'])\n",
    "    return (dt_obj2-dt_obj1).total_seconds()/60\n",
    "\n",
    "def intime(row):\n",
    "    dt_obj1 = parser.parse(row['indate'].split()[0]+' 00:00:00')\n",
    "    dt_obj2 = parser.parse(row['indate'])\n",
    "    return (dt_obj2-dt_obj1).total_seconds()/3600\n",
    "\n",
    "def indatetime(row, start):\n",
    "    dt_obj1 = parser.parse(start)\n",
    "    dt_obj2 = parser.parse(row['indate'])\n",
    "    return (dt_obj2-dt_obj1).total_seconds()/3600\n",
    "\n",
    "def load_bases(paths, date, plotting=False, names=None):\n",
    "    pd.set_option('display.max_columns', None)  # or 1000\n",
    "    pd.set_option('display.max_rows', None)  # or 1000\n",
    "    pd.set_option('display.max_colwidth', 100)  # or 199\n",
    "    pd.options.display.expand_frame_repr = False\n",
    "    dfs = [0]*len(paths)\n",
    "    for i in range(len(paths)):\n",
    "        dfs[i] = pd.read_csv(paths[i],error_bad_lines=False, sep=\";\")\n",
    "        dfs[i]['stopdate'].replace('', np.nan, inplace=True)\n",
    "        dfs[i].dropna(subset=['stopdate'], inplace=True)\n",
    "        dfs[i][\"exec\"] = dfs[i].apply (lambda row: timetoclass(row), axis=1)\n",
    "        dfs[i][\"exec_min\"] = dfs[i].apply (lambda row: timedif(row), axis=1)\n",
    "        dfs[i][\"intime\"] = dfs[i].apply (lambda row: intime(row), axis=1)\n",
    "        dfs[i][\"indatetime\"] = dfs[i].apply (lambda row: indatetime(row, dfs[i]['indate'].min()), axis=1)\n",
    "        dfs[i] = dfs[i].loc[dfs[i]['ntime']<=1440]\n",
    "        dfs[i] = dfs[i].loc[dfs[i]['nproc']<=2000]\n",
    "        dfs[i] = dfs[i].loc[dfs[i]['exec_min']<=dfs[i]['ntime']]\n",
    "        if plotting:\n",
    "            plt.rcParams['figure.dpi'] = 200\n",
    "            plt.rcParams['savefig.dpi'] = 200\n",
    "            ax1 = plt.subplot(221+i)\n",
    "            sns.distplot(dfs[i]['exec']).set_title(\"Distribution of exec in \"+names[i])\n",
    "            ax1.set_xlim(0, 25)\n",
    "            plt.show()\n",
    "    return dfs\n",
    "\n",
    "def plot_cmdline_stats(dfs, names):    \n",
    "    fig, axs = plt.subplots(len(paths), 1, figsize=(5,10))\n",
    "    fig.tight_layout(pad=5.0)\n",
    "    for i in range(len(paths)):\n",
    "        df = dfs[i]\n",
    "        cmds = {}\n",
    "        for s in df['cmdline']:\n",
    "            cnt = len(s.split())\n",
    "            if cnt not in cmds:\n",
    "                cmds[cnt] = 1\n",
    "            else:\n",
    "                cmds[cnt] += 1\n",
    "        s_cmds = {c:cmds[c] for c in sorted(cmds)}\n",
    "        axs[i].bar([f'{i}' for i in s_cmds.keys()], s_cmds.values(),linewidth=100)\n",
    "        axs[i].set_title(names[i])\n",
    "        axs[i].set_ylabel(\"кол-во задач\")\n",
    "        axs[i].set_xlabel(\"кол-во параметров\")\n",
    "    plt.show()\n",
    "    \n",
    "def cmd_keys_stats(dfs, names):\n",
    "    for k in range(len(dfs)):\n",
    "        df = dfs[k]\n",
    "        cmds = {}\n",
    "        cmd_list = df['cmdline'].tolist()\n",
    "        for i in range(len(cmd_list)):\n",
    "            s = cmd_list[i]\n",
    "            local_list = []\n",
    "            for ss in s.split():\n",
    "                for sss in ss.split('/'):\n",
    "                    if sss != '':\n",
    "                        local_list.append(sss)\n",
    "            for j in range(len(local_list)-1):\n",
    "                if local_list[j] is None or len(local_list[j])==0:\n",
    "                    continue\n",
    "                if local_list[j][0] == '-' and local_list[j+1][0] != '-':\n",
    "                    local_list[j] = local_list[j]+\" \"+local_list[j+1]\n",
    "                    #print(local_list[j])\n",
    "                    local_list[j+1] = None\n",
    "\n",
    "            for sss in local_list:\n",
    "                if sss is None:\n",
    "                    continue\n",
    "                if sss not in cmds:\n",
    "                    cmds[sss] = 1\n",
    "                else:\n",
    "                    cmds[sss] += 1\n",
    "        s_cmds ={k: v for k, v in sorted(cmds.items(), key=lambda item: -item[1]) if cmds[k] > 200 and not \"home\" in k and not \"pstorage\" in k and '' != k and '.'!=k} \n",
    "        print(names[k])\n",
    "        print(s_cmds)\n",
    "        print('\\n')\n",
    "\n",
    "        \n",
    "def unique_cmd_stat(dfs, names):\n",
    "    fig, axs = plt.subplots(len(paths), 1, figsize=(5,10))\n",
    "    fig.tight_layout(pad=5.0)\n",
    "    s_cmds_arr = []\n",
    "    for i in range(len(dfs)):\n",
    "        df = dfs[i]\n",
    "        cmds = {}\n",
    "        for index, row in df.iterrows():\n",
    "                uid = row['userid']\n",
    "                if uid not in cmds:\n",
    "                    cmds[uid] = [row['cmdline']]\n",
    "                else:\n",
    "                    cmds[uid].append(row['cmdline'])\n",
    "        s_cmds ={k: v for k, v in sorted(cmds.items(), key=lambda item: -len(item[1]))} \n",
    "        s_cmds_arr.append(s_cmds)\n",
    "        for x in s_cmds:\n",
    "            print(x, \" - \", len(s_cmds[x]), \" - \", len(set(s_cmds[x])))\n",
    "        v1 = [ len(set(s_cmds[x])) for x in s_cmds]\n",
    "        v2 = [ len(s_cmds[x]) - len(set(s_cmds[x])) for x in s_cmds]\n",
    "        v1,v2 = v1[:40], v2[:40]\n",
    "\n",
    "        axs[i].bar([i for i in range(len(v1))], v1 ,linewidth=100, label = \"Уникальне команды\")\n",
    "        axs[i].bar([i for i in range(len(v1))], v2, bottom=v1 ,linewidth=100,  label = \"Повторные команды\")\n",
    "        axs[i].set_title(names[i])\n",
    "        axs[i].set_ylabel(\"кол-во пусков\")\n",
    "        axs[i].set_xlabel(\"пользователь\")\n",
    "        axs[i].legend()\n",
    "    return s_cmds_arr\n",
    "\n",
    "def vif_stat(dfs, names):\n",
    "    for k in range(len(dfs)):\n",
    "        df = dfs[k]\n",
    "        df = df.drop(columns=['indate','taskname', 'exittype', 'cmdline', 'rundate', 'stopdate', 'userid', 'indatetime'])\n",
    "        df = df.dropna()\n",
    "        df = df._get_numeric_data()\n",
    "        # VIF dataframe\n",
    "        vif_data = pd.DataFrame()\n",
    "        vif_data[\"feature\"] = df.columns\n",
    "        # calculating VIF for each feature\n",
    "        vif_data[\"VIF\"] = [variance_inflation_factor(df.values, i)\n",
    "                                  for i in range(len(df.columns))]\n",
    "        print(names[k], vif_data)\n",
    "\n",
    "def normalize_data(dfs, names = None, plotting=True):\n",
    "    new_dfs = []\n",
    "    for k in range(len(dfs)):\n",
    "        df = dfs[k]\n",
    "        dfdel = df.loc[df['ntime'] - df['exec_min'] <= 0.05]\n",
    "        df = df.loc[df['ntime'] - df['exec_min'] > 0.05]\n",
    "        df = df.sort_values(by=['indate'])\n",
    "        df = df.drop(columns=['indate', 'rundate', 'stopdate', 'exittype', 'exec_min', 'taskname', 'indatetime'])\n",
    "\n",
    "        col_to_dict = ['userid', 'gid', 'orgid']\n",
    "        dicts = {'userid':{}, 'gid':{}, 'orgid':{}}\n",
    "        for col in col_to_dict:\n",
    "            for d in df[col]:\n",
    "                if d in dicts[col]:\n",
    "                    dicts[col][d]+=1\n",
    "                else:\n",
    "                    dicts[col][d]=1\n",
    "            df[col] = [list(dicts[col]).index(d) for d in df[col]]\n",
    "\n",
    "        col_to_norm = ['nproc','ntime','userid','gid','orgid','intime']\n",
    "        for col in col_to_norm:\n",
    "            colmin = df[col].min()\n",
    "            colmax = df[col].max()\n",
    "            if col in ['ntime']:\n",
    "                dfdel.loc[:, col] = (dfdel[col] - colmin) / (colmax - colmin)\n",
    "            df.loc[:, col] = (df[col] - colmin) / (colmax - colmin)\n",
    "        new_dfs.append(df)\n",
    "        # probability plot\n",
    "        if plotting:\n",
    "            plt.rcParams['figure.dpi'] = 200\n",
    "            plt.rcParams['savefig.dpi'] = 200\n",
    "            plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1,\n",
    "                    right=0.9,\n",
    "                    top=0.9,\n",
    "                    wspace=0.5,\n",
    "                    hspace=1.5)\n",
    "            if names is None:\n",
    "                names = ['_']*len(dfs)\n",
    "            ax1 = plt.subplot(21 + 100*len(dfs)+ 2*k)\n",
    "            sns.distplot(df['exec']).set_title(f\"Distribution of exec in {names[k]}\")\n",
    "            ax1 = plt.subplot(22 + 100*len(dfs)+ 2*k)\n",
    "            res = scipy.stats.probplot(df['exec'], plot=plt)\n",
    "            #ax1 = plt.subplot(43 + 100*len(dfs)+ 4*k)\n",
    "            #sns.distplot(df['nproc']).set_title(\"Distribution of nproc\")\n",
    "            #ax1 = plt.subplot(44 + 100*len(dfs)+ 4*k)\n",
    "            #res = scipy.stats.probplot(df['nproc'], plot=plt)\n",
    "            \n",
    "            \"\"\"\n",
    "            plt.figure()\n",
    "            plt.scatter(df['exec'], df['ntime'], s=5, label='Отобранные данные')\n",
    "            plt.scatter(dfdel['exec'], dfdel['ntime'], s=5, c='red', label='Неподходящие данные')\n",
    "            plt.ylabel('Запрошенное время(мин)', fontsize=12)\n",
    "            plt.xlabel('Время выполнения(мин)', fontsize=12)\n",
    "            plt.legend(loc='lower right')\n",
    "            \"\"\"\n",
    "            \n",
    "    return new_dfs\n",
    "\n",
    "def prepare_cmd_data(dfs):\n",
    "    cmd_data = []\n",
    "    global_keys = []\n",
    "    global_names = []\n",
    "    for df in dfs:\n",
    "        X = df.drop(columns=['exec'])\n",
    "        program_data = ['']*len(X['cmdline'])\n",
    "        cmd_dict = {\"cmd_{}\".format(i+1):([-1]*len(X['cmdline'])) for i in range(20)}\n",
    "        keys = set()\n",
    "        program_names = set()\n",
    "        key_table = [[]]*len(X['cmdline'])\n",
    "        for ii, s in enumerate(X['cmdline']):\n",
    "            pas = False\n",
    "            k = []\n",
    "            program_name = s.split(' ')[0].split('/')[-1]\n",
    "            program_names.add(program_name)\n",
    "            for idx, ss in enumerate(s.split()):\n",
    "                if pas:\n",
    "                    pas = False\n",
    "                    continue\n",
    "                if ss[0]=='-' and idx<len(s.split())-1 and s.split()[idx+1][0]!='-':\n",
    "                    keys.add(ss+' '+s.split()[idx+1])\n",
    "                    k.append(ss+' '+s.split()[idx+1])\n",
    "                    pas = True\n",
    "                else:\n",
    "                    keys.add(ss)\n",
    "                    k.append(ss)\n",
    "            #print(ii)\n",
    "            key_table[ii] = k\n",
    "            program_data[ii] = program_name\n",
    "        keys = list(keys)\n",
    "        program_names = list(program_names)\n",
    "        #print(program_names)\n",
    "        cmd_table = np.zeros((len(X['cmdline']), len(keys)), dtype=np.int32)\n",
    "        for idx, ss in enumerate(key_table):\n",
    "            program_data[idx] = program_names.index(program_data[idx])\n",
    "            #for s in ss:\n",
    "                #cmd_table[idx][keys.index(s)] = 1\n",
    "            key_list = []\n",
    "            for k in range(len(ss)):\n",
    "                key_list.append(keys.index(ss[k]))\n",
    "            key_list = sorted(key_list, reverse=True)\n",
    "            #print(key_list)\n",
    "            for k in range(len(key_list)):\n",
    "                cmd_dict[\"cmd_{}\".format(k+1)][idx]=key_list[k]\n",
    "            \n",
    "        for i in range(20):\n",
    "            s = \"cmd_{}\".format(i+1)\n",
    "            X[s] = cmd_dict[s]\n",
    "        X['program_names'] = program_data\n",
    "        X = X.drop(columns=['cmdline'])\n",
    "        X = X.astype(np.float64)\n",
    "        cmd_data.append(X)\n",
    "        global_keys.append(keys)\n",
    "        global_names.append(program_names)\n",
    "    return cmd_data, global_keys, global_names\n",
    "\n",
    "def generate_train_test_data(dfs,cmd_data, test_percent = 0.05):\n",
    "    X_trains, X_tests, y_trains, y_tests = [],[],[],[]\n",
    "    for i in range(len(dfs)):\n",
    "        df = dfs[i]\n",
    "        X = cmd_data[i]\n",
    "        y = df.loc[:,['userid', 'exec']]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_percent, shuffle=True)\n",
    "\n",
    "        userdict = {}\n",
    "        for u in X_train['userid']:\n",
    "            if u in userdict:\n",
    "                userdict[u]+=1\n",
    "            else:\n",
    "                userdict[u]=1\n",
    "\n",
    "        for u in X_test['userid']:\n",
    "            if u not in userdict:\n",
    "                userdict[u]=0\n",
    "\n",
    "        X_trains.append(X_train.loc[[userdict[user] > 3 for user in X_train['userid']]])\n",
    "        X_tests.append(X_test.loc[[userdict[user] > 3 for user in X_test['userid']]])\n",
    "        y_train = y_train.loc[[userdict[user] > 3 for user in y_train['userid']]]\n",
    "        y_test = y_test.loc[[userdict[user] > 3 for user in y_test['userid']]]\n",
    "        y_tests.append(y_test.drop(columns=['userid']))\n",
    "        y_trains.append(y_train.drop(columns=['userid']))\n",
    "    return X_trains, X_tests, y_trains, y_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7837bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_idx = 2\n",
    "group_idx = 3\n",
    "org_idx = 4\n",
    "cmd_idx = 5\n",
    "intime_idx = 6\n",
    "i = 0\n",
    "def custom_metric(X1, X2, **kwargs):\n",
    "    au = kwargs[\"au\"]\n",
    "    ag = kwargs[\"ag\"]\n",
    "    ao = kwargs[\"ao\"]\n",
    "    d = 0\n",
    "    if X1[user_idx]!=X2[user_idx]:\n",
    "        d+=au\n",
    "    if X1[group_idx]!=X2[group_idx]:\n",
    "        d+=ag\n",
    "    if X1[org_idx]!=X2[org_idx]:\n",
    "        d+=ao\n",
    "    for idx in range(2):\n",
    "            dif = (X1[idx] - X2[idx])**2\n",
    "            d+=dif\n",
    "    d+=(X1[intime_idx] - X2[intime_idx])**2\n",
    "    d += sum(abs(cmd_table[int(X1[cmd_idx])] - cmd_table[int(X2[cmd_idx])]))/len(cmd_table[0])\n",
    "            \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395cccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "%%cython --annotate -n custom_metric_c\n",
    "from libc.math cimport abs\n",
    "from libc.stdio cimport printf\n",
    "from libc.stdlib cimport malloc, free\n",
    "\n",
    "\n",
    "def cython_f(double[:] X1, double[:] X2, int p = 2, double w = -1):\n",
    "    cdef double d = 0\n",
    "    cdef double dif = 0\n",
    "    cdef root_w = 1\n",
    "    if w != -1:\n",
    "        root_w = sqrt(w)\n",
    "    for idx in range(6):\n",
    "        dif = (root_w*(X1[idx] - X2[idx]))**2\n",
    "        d+=dif\n",
    "    dif = 0\n",
    "    for i in range(6,6+20):\n",
    "        for j in range(6,6+20):\n",
    "            if (X1[i] == X2[j]):\n",
    "                continue;\n",
    "            if X1[i] > X2[j] or j == 25:\n",
    "                dif+=1\n",
    "                continue;\n",
    "    d+=dif/1000\n",
    "    return sqrt(d)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0281d4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cython_metric.pyx\n",
    "from libc.math cimport sqrt, abs\n",
    "from libc.stdio cimport printf\n",
    "from libc.stdlib cimport malloc, free\n",
    "\n",
    "cdef int* cmd_table\n",
    "cdef int cmd_table_len\n",
    "cdef int cmd_table_h\n",
    "cdef int user_idx = 2\n",
    "cdef int group_idx = 3\n",
    "cdef int org_idx = 4\n",
    "cdef int intime_idx = 5\n",
    "\n",
    "def cython_metric(double[:] X1, double[:] X2, int p = 2, double w = -1):\n",
    "    cdef double d = 0\n",
    "    cdef double dif = 0\n",
    "    cdef root_w = 1\n",
    "    if w != -1:\n",
    "        root_w = sqrt(w)\n",
    "    for idx in range(6):\n",
    "        dif = (root_w*(X1[idx] - X2[idx]))**2\n",
    "        d+=dif\n",
    "    dif = 0\n",
    "    for i in range(6,6+20):\n",
    "        for j in range(6,6+20):\n",
    "            if (X1[i] == X2[j]):\n",
    "                break;\n",
    "            if X1[i] > X2[j] or j == 25:\n",
    "                dif+=1\n",
    "                break;\n",
    "    d+=d*(dif/100)\n",
    "    return sqrt(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec9e6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cython_metric_v2.pyx\n",
    "from libc.math cimport sqrt, abs\n",
    "from libc.stdio cimport printf\n",
    "from libc.stdlib cimport malloc, free\n",
    "\n",
    "cdef int* cmd_table\n",
    "cdef int cmd_table_len\n",
    "cdef int cmd_table_h\n",
    "cdef int user_idx = 2\n",
    "cdef int group_idx = 3\n",
    "cdef int org_idx = 4\n",
    "cdef int intime_idx = 5\n",
    "\n",
    "def cython_metric_v2(double[:] X1, double[:] X2, int p = 2, double w = -1):\n",
    "    cdef double d = 0\n",
    "    cdef double dif = 0\n",
    "    cdef root_w = 1\n",
    "    if w != -1:\n",
    "        root_w = sqrt(w)\n",
    "    for idx in range(6):\n",
    "        dif = (root_w*(X1[idx] - X2[idx]))**2\n",
    "        d+=dif\n",
    "    \n",
    "    if X1[user_idx]!=X2[user_idx]:\n",
    "        d+=1\n",
    "        \n",
    "    dif = 0   \n",
    "    for i in range(6,6+20):\n",
    "        for j in range(6,6+20):\n",
    "            if (X1[i] == X2[j]):\n",
    "                break;\n",
    "            if X1[i] > X2[j] or j == 25:\n",
    "                dif+=1\n",
    "                break;\n",
    "    d+=(dif/100)\n",
    "    return sqrt(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e0bc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile minkovski_metric.pyx\n",
    "from libc.math cimport sqrt, abs\n",
    "from libc.stdio cimport printf\n",
    "from libc.stdlib cimport malloc, free\n",
    "\n",
    "cdef int* cmd_table\n",
    "cdef int cmd_table_len\n",
    "cdef int cmd_table_h\n",
    "cdef int user_idx = 2\n",
    "cdef int group_idx = 3\n",
    "cdef int org_idx = 4\n",
    "cdef int intime_idx = 5\n",
    "\n",
    "def minkovski_metric(double[:] u, double[:] v, int p = 2, double w = -1):\n",
    "    cdef double d = 0\n",
    "    cdef root_w = 1\n",
    "    if w != -1:\n",
    "        root_w = sqrt(w)\n",
    "    for idx in range(6):\n",
    "        d+=(root_w*(u[idx]-v[idx]))**2\n",
    "    return sqrt(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704d50de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile setup.py\n",
    "from distutils.core import setup\n",
    "from Cython.Build import cythonize\n",
    "\n",
    "setup(name=\"cython_metric\", ext_modules=cythonize('cython_metric.pyx'))\n",
    "#setup(name=\"minkovski_metric\", ext_modules=cythonize('minkovski_metric.pyx'))\n",
    "setup(name=\"cython_metric_v2\", ext_modules=cythonize('cython_metric_v2.pyx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d4efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python setup.py build_ext --inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca95f03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cython_metric import cython_metric\n",
    "from minkovski_metric import minkovski_metric\n",
    "#train_d = X_train.drop(columns=[\"cmd_{}\".format(i+1) for i in range(20)])\n",
    "#z = train_d.values[:2]\n",
    "#print(z[0], z[1])\n",
    "def python_metric( X1,  X2,  p = 2,  w = -1):\n",
    "    d = 0\n",
    "    dif = 0\n",
    "    root_w = 1\n",
    "    if w != -1:\n",
    "        root_w = sqrt(w)\n",
    "    for idx in range(6):\n",
    "        dif = (root_w*(X1[idx] - X2[idx]))**2\n",
    "        d+=dif\n",
    "    dif = 0\n",
    "    for i in range(6,6+20):\n",
    "        for j in range(6,6+20):\n",
    "            if (X1[i] == X2[j]):\n",
    "                break;\n",
    "            if X1[i] > X2[j] or j == 25:\n",
    "                dif+=1\n",
    "                break;\n",
    "    print(dif)\n",
    "    d+=dif/1000\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6a07f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cython_metric import cython_metric\n",
    "from minkovski_metric import minkovski_metric\n",
    "from cython_metric_v2 import cython_metric_v2\n",
    "ridge_param = {\n",
    "    'alpha': [ 0.6, 0.7, 0.75, 0.8, 0.9],\n",
    "    'fit_intercept':[True, False],\n",
    "    'normalize':[True, False],\n",
    "    'solver':['svd'],\n",
    "    'class_weight':[None, 'balanced']\n",
    "}\n",
    "\n",
    "tree_param = {\n",
    "    \"splitter\":[\"best\",\"random\"],\n",
    "    \"max_depth\" : [10, 15, 20, 25,30, 50],\n",
    "    \"min_samples_leaf\":[2,3,4,5,6,7,8,9,10],\n",
    "    \"criterion\": ['entropy', 'gini'],\n",
    "    \"max_leaf_nodes\":[None,10,20,30,40,50,60,70,80,90] \n",
    "    }\n",
    "\n",
    "forest_param = {\n",
    "    \"n_estimators\":[50,100],\n",
    "    \"max_depth\" : [ 25]\n",
    "}\n",
    "\n",
    "knn_param_no_cmd = {\n",
    "    \"algorithm\":['ball_tree', 'brute'],\n",
    "    \"n_neighbors\":[16, 20, 24,28],\n",
    "    #'metric':[minkovski_metric],\n",
    "    \"weights\":['uniform', 'distance'],\n",
    "}\n",
    "\n",
    "knn_param = {\n",
    "    \"algorithm\":['ball_tree', 'brute'],\n",
    "    \"n_neighbors\":[16, 20, 24,28],\n",
    "    'metric':[cython_metric],\n",
    "    \"weights\":['uniform', 'distance'],\n",
    "    }\n",
    "knnv2_param = {\n",
    "    \"algorithm\":['ball_tree', 'brute'],\n",
    "    \"n_neighbors\":[2,3,4,5],\n",
    "    'metric':[cython_metric_v2],\n",
    "    \"weights\":['uniform', 'distance'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca7a902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_program_trees(X_trains,y_trains,cmd_data, glob_keys, glob_prog_names):\n",
    "    program_trees_global = [0]*len(dfs)\n",
    "    program_keys_global = [0]*len(dfs)\n",
    "    \n",
    "    params = {\n",
    "        \"splitter\":[\"best\",\"random\"],\n",
    "        \"max_depth\" : [5,7,10,12],\n",
    "        \"min_samples_leaf\":[2,3,4,5,6,7,8,9,10],\n",
    "        \"criterion\": ['entropy', 'gini'],\n",
    "        \"max_leaf_nodes\":[None,10,20,30,40,50,60,70,80,90] \n",
    "    }\n",
    "    for i in range(len(dfs)):\n",
    "        program_trees = {}\n",
    "        program_keys = {}\n",
    "        df = X_trains[i].join(y_trains[i])\n",
    "        keys = glob_keys[i]\n",
    "        prog_names = glob_prog_names[i]\n",
    "        for name in prog_names:\n",
    "            df_prog = df.loc[df['program_names'] == prog_names.index(name)]\n",
    "            if df_prog.shape[0] >= 0.03*df.shape[0]:\n",
    "                local_key_d = {}\n",
    "                df_prog = df_prog.reset_index() \n",
    "                for index, row in df_prog.iterrows():\n",
    "                    for k in range(1,21):\n",
    "                        key = row[\"cmd_{}\".format(k)]\n",
    "                        if key in local_key_d.keys():\n",
    "                            local_key_d[key] += 1\n",
    "                        else:\n",
    "                            local_key_d[key] = 1\n",
    "                keys_to_check = list(local_key_d.keys())\n",
    "                for key in keys_to_check:\n",
    "                    if local_key_d[key] < 0.03*df_prog.shape[0]:\n",
    "                        del local_key_d[key]\n",
    "                tree_test_data = df_prog.loc[:, [\"cmd_{}\".format(k) for k in range(1,21)] + [\"exec\"]]\n",
    "                for j in range(len(local_key_d)):\n",
    "                    tree_test_data[f\"t_cmd_{j}\"] = tree_test_data.apply(lambda row: 0 if list(local_key_d.keys())[j] not in [row[\"cmd_{}\".format(k)] for k in range(1,21)] else 1,  axis=1)\n",
    "                tree_test_data = tree_test_data.drop(columns= [\"cmd_{}\".format(k) for k in range(1,21)])\n",
    "                tree_test_data = tree_test_data.loc[sum([tree_test_data[f\"t_cmd_{j}\"] for j in range(len(local_key_d))]) > 0]\n",
    "                #print(tree_test_data.describe(),df_prog.loc[:,[\"exec\"]].describe(), name, df_prog.shape[0], len(local_key_d))\n",
    "                cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "                search = GridSearchCV(tree.DecisionTreeClassifier(), params, scoring='f1_weighted', n_jobs=-1, cv=cv)\n",
    "                result = search.fit(tree_test_data.drop(columns= [\"exec\"]), tree_test_data.loc[:,[\"exec\"]])\n",
    "                print('Best Score: %s' % result.best_score_)\n",
    "                print('Best Hyperparameters: %s' % result.best_params_)\n",
    "                program_trees[name] = search.best_estimator_\n",
    "                program_keys[name] = list(local_key_d.keys())\n",
    "        program_trees_global[i] = program_trees\n",
    "        program_keys_global[i] = program_keys\n",
    "    return program_trees_global, program_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aae9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = \"04_04_23\"\n",
    "paths = [\".\\\\run_info\\\\broadwell_\"+date+\".csv\", \".\\\\run_info\\\\cascade_lake_\"+date+\".csv\", \".\\\\run_info\\\\skylake_\"+date+\".csv\"]\n",
    "names = [\"broadwell\", \"cascade_lake\", \"skylake\"]\n",
    "dfs = load_bases(paths, date, plotting=True, names=names)\n",
    "#plot_cmdline_stats(dfs, names)\n",
    "#cmd_keys_stats(dfs, names)\n",
    "#s_cmds_arr = unique_cmd_stat(dfs, names)\n",
    "#vif_stat(dfs, names)\n",
    "dfs_n = normalize_data(dfs, names=names, plotting=False)#, plotting=False\n",
    "cmd_data, keys, prog_names = prepare_cmd_data(dfs_n)\n",
    "#print(prog_names)\n",
    "X_trains, X_tests, y_trains, y_tests = generate_train_test_data(dfs_n, cmd_data,test_percent = 0.10)\n",
    "dfs_n[1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05edde1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#program_trees_global = prepare_program_trees(X_trains,y_trains ,cmd_data, keys, prog_names)\n",
    "#X_trains[0].join(y_trains[0]).head(10)\n",
    "#X_tests[0].describe()\n",
    "cmd_data[0][dfs[0][\"orgid\"]==122]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a62560",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "total_results = {}\n",
    "outputs = {}\n",
    "for i in range(len(dfs)):\n",
    "    print(names[i])\n",
    "    X_train, X_test, y_train, y_test = X_trains[i], X_tests[i], y_trains[i], y_tests[i]\n",
    "    #program_trees = program_trees_global[i]\n",
    "    w = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "    y_w = y_train['exec'].values.tolist()\n",
    "    #print(w, y_w)\n",
    "    #real_weights = [w[y_w.index(i)] for i in range(24)]\n",
    "    models = {\n",
    "        #'knn':KNeighborsClassifier(),\n",
    "        #'knnv2':KNeighborsClassifier(),\n",
    "        'ridge':RidgeClassifier(),\n",
    "        'tree':tree.DecisionTreeClassifier(),\n",
    "        'forest': RandomForestClassifier(),\n",
    "        #'knn without cmd':KNeighborsClassifier(),\n",
    "        }\n",
    "\n",
    "    params = {\n",
    "        'knn' : knn_param,\n",
    "        'knnv2' : knnv2_param,\n",
    "        'ridge': ridge_param,\n",
    "        'tree': tree_param,\n",
    "        'forest': forest_param,\n",
    "        'knn without cmd' : knn_param_no_cmd,\n",
    "    }\n",
    "    output = {}\n",
    "    results = {}\n",
    "    #w = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "    for m in models:\n",
    "        print(m)\n",
    "        train_data = X_train\n",
    "        test_data = X_test\n",
    "        #if m == 'tree':\n",
    "        #    train_data = program_k_decision(train_data, program_trees)\n",
    "        if m!='knn' and m!=\"knnv2\":\n",
    "            train_data = train_data.drop(columns=[\"cmd_{}\".format(i+1) for i in range(20)])\n",
    "            test_data = test_data.drop(columns=[\"cmd_{}\".format(i+1) for i in range(20)])\n",
    "        #print(train_data.describe())\n",
    "        cv = ShuffleSplit(n_splits=5, test_size=0.1)#, random_state=0\n",
    "        #search = RandomizedSearchCV(models[m], params[m], scoring='accuracy', n_jobs=-1, cv=cv, n_iter=30)\n",
    "        search = GridSearchCV(models[m], params[m], scoring='f1_micro', n_jobs=-1, cv=cv)\n",
    "        if m.find('knn') < 0:\n",
    "            result = search.fit(train_data, y_train,sample_weight=w)\n",
    "        else:\n",
    "            result = search.fit(train_data, y_train)\n",
    "        best = search.best_estimator_\n",
    "        output[m] = best.predict(test_data)\n",
    "        results[m] = result\n",
    "        print('Best Score: %s' % result.best_score_)\n",
    "        print('Best Hyperparameters: %s' % result.best_params_)\n",
    "    total_results[names[i]] = results\n",
    "    outputs[names[i]] = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdec371",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dfs)):\n",
    "    print(names[i])\n",
    "    y = y_tests[i]\n",
    "    #plt.figure()\n",
    "    x = range(len(y['exec']))\n",
    "    #plt.scatter(x, y['exec'], s=5, label='real')\n",
    "    out = outputs[names[i]]\n",
    "    for m in models:\n",
    "        #plt.scatter(x, y[m], s=5, label=m)\n",
    "        print(m)\n",
    "        print(classification_report(y['exec'], out[m], digits=4))\n",
    "        print(m + \" accuracy \", accuracy_score(y['exec'], out[m]))\n",
    "        print(m + \" F1 \", f1_score(y['exec'], out[m], average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f67586e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(str, set(y_train['exec'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752d175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "res1 = copy.deepcopy(results)\n",
    "print(res0, res1)\n",
    "#best = tree.DecisionTreeRegressor(**(results['tree'].best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ebe33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0896d1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
